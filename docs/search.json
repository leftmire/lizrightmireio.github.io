[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog\nMy name is Liz Rightmire\nI’m a computer science student at Middlebury College\nThis blog holds the work I’ve done in CSCI0451: Machine Learning"
  },
  {
    "objectID": "posts/new-new-test-post/index.html",
    "href": "posts/new-new-test-post/index.html",
    "title": "Timnit Gebru",
    "section": "",
    "text": "from source import Perceptron\np = Perceptron()\n\nI did it!!\nnot implemented\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-new-test-post/index.html#math",
    "href": "posts/new-new-test-post/index.html#math",
    "title": "Timnit Gebru",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/example-blog-post/index.html",
    "href": "posts/example-blog-post/index.html",
    "title": "Hello Blog",
    "section": "",
    "text": "from source import Perceptron\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/example-blog-post/index.html#math",
    "href": "posts/example-blog-post/index.html#math",
    "title": "Hello Blog",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/new-test-post/index.html",
    "href": "posts/new-test-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "This is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-test-post/index.html#math",
    "href": "posts/new-test-post/index.html#math",
    "title": "Second Post",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Liz’s CSCI 0451 Blog",
    "section": "",
    "text": "Classifying Palmer Penguins\n\n\n\n\n\nSelecting features and model for accurate penguin species classifier\n\n\n\n\n\nFeb 20, 2024\n\n\nLiz Rightmire\n\n\n\n\n\n\n\n\n\n\n\n\nSecond Post\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\n\n\n\n\n\n\nTimnit Gebru\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\n\n\n\n\n\n\nGoal Setting\n\n\n\n\n\nGoal setting for beginning of semester\n\n\n\n\n\nJan 10, 2023\n\n\nLiz Rightmire\n\n\n\n\n\n\n\n\n\n\n\n\nHello Blog\n\n\n\n\n\nAn example blog post illustrating the key techniques you’ll need to demonstrate your learning in CSCI 0451.\n\n\n\n\n\nJan 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/ClassifyingPalmerPenguins/index.html",
    "href": "posts/ClassifyingPalmerPenguins/index.html",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "CSCI 0451\n\nClassifying Palmer Penguins\n\n\n\ncite: https://education.rstudio.com/blog/2020/07/palmerpenguins-cran/\n\n\nThe Palmer Penguins dataset is a public dataset frequently used within the educational data science community. It contains Dr. Kristen Gorman and the Long Term Ecological Research Network’s observations of hundreds of antartic penguins belonging to 3 species groups: Adelie, Gentoo, and Chinstrap.\nThis blog aims to accomplish three goals:\n\nConduct exploration of the Palmer Penguins dataset\nMethodically select 3 features and a model type that produces 100% penguin species classification accuracy on test data\nEvaluate chosen model by analyzing decision regions and a confusion matrix\n\n\nRandom Exploration\n\nimport pandas as pd\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\ntrain[\"Species\"] = train[\"Species\"].str.split().str.get(0)\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN\n\n\n\n\n\n\n\nThe training data contains 18 observations about 275 penguin subjects. Let’s clean this data by dropping irrelevent columns and one-hot encoding the qualitative observations.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1)\n  df = df[df[\"Sex\"] != \".\"]\n  df = df.dropna()\n  y = le.transform(df[\"Species\"])\n  df = df.drop([\"Species\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(train)\nX_train\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nStage_Adult, 1 Egg Stage\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40.9\n16.6\n187.0\n3200.0\n9.08458\n-24.54903\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n1\n49.0\n19.5\n210.0\n3950.0\n9.53262\n-24.66867\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n2\n50.0\n15.2\n218.0\n5700.0\n8.25540\n-25.40075\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n3\n45.8\n14.6\n210.0\n4200.0\n7.79958\n-25.62618\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n4\n51.0\n18.8\n203.0\n4100.0\n9.23196\n-24.17282\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n270\n51.1\n16.5\n225.0\n5250.0\n8.20660\n-26.36863\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n271\n35.9\n16.6\n190.0\n3050.0\n8.47781\n-26.07821\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\nTrue\nFalse\n\n\n272\n39.5\n17.8\n188.0\n3300.0\n9.66523\n-25.06020\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n273\n36.7\n19.3\n193.0\n3450.0\n8.76651\n-25.32426\nFalse\nFalse\nTrue\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n274\n42.4\n17.3\n181.0\n3600.0\n9.35138\n-24.68790\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n\n\n256 rows × 14 columns\n\n\n\nVisualizations\n\nimport seaborn as sns\nsns.set_palette(\"husl\", 3)\n\n# visualization 1: flipper length frequency by species\nsns.histplot(data = train, x = \"Flipper Length (mm)\", hue = \"Species\", bins = 25, edgecolor = 'grey')\n\n/Users/lizrightmire/anaconda3/envs/ml-0451/lib/python3.9/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n\n\n\n\n\n\n\n\n\nThis histogram shows the distribution of the penguins’ flipper lengths. The bars are colored based on penguin species, so the shape of the distributions allow the viewer to infer the mean, medians, and modes for each species. There is a trend in flipper length based on species: Gentoo penguins tend to have the largest flippers, and Adelie and Chinstrap penguins have smaller ones. This indicates that flipper length may be a helpful feature to use in classification, as it effectively identifies the Gentoo penguins from the rest of the species.\n\n# visualization 2: body mass vs. culmen length\nplot1 = sns.scatterplot(train, x = \"Body Mass (g)\", y = \"Culmen Length (mm)\", hue = \"Species\")\n\n\n\n\n\n\n\n\nAfter considering multiple combinations of qualitative features in scatterplots, body mass and culmen length proved to show clear groupings of penguin species. Therefore, these two features are likely to be effective in a classification model. That being said, overlap does exist, especially between Adelie and Gentoo penguins.\n\n# summary table\ntable = train.groupby(['Species', 'Island']).size()\ntable\n\nSpecies    Island   \nAdelie     Biscoe       33\n           Dream        45\n           Torgersen    42\nChinstrap  Dream        57\nGentoo     Biscoe       98\ndtype: int64\n\n\nThis summary table shows the numbers of penguins present on each island. Every penguin on Torgersen island is an Adelie penguin, and both Gentoo and Chinstrap penguins can only be found on one island. These clear trends cause me to consider island location as a potential feature in a classification model.\n\n\n\ncite: https://en.ac-illust.com/clip-art/22518802/illustration-of-a-cute-penguins-playing-a-computer\n\n\n\n\nChoosing Features\nBecause there were only 5 qualitative and 6 quantitative feature in the cleaned dataset, I chose to perform an exhaustive search to determine the most effective features and model for species classification. For each combination of 2 quantitative and 1 qualitative feature, I fit 4 models: Logistic Regression, Decision Tree, Random Forest, and SVM. Cross validation was performed to guard against overfitting as follows:\n\nLogistic Regression: recorded average accuracy of 5 rounds, each round with a random 20% of data used for testing\nDecision Tree and Random Forest: performed grid search of varrying max_depth values, recorded highest accuracy achieved\nSVM: performed grid search of varrying gamma values, recorded highest accuracy achieved\n\n\nfrom itertools import combinations\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\n\npd.set_option('max_colwidth', 10000)\n\nall_qual_cols = [\"Clutch Completion\", \"Sex\", \"Island\", 'Stage_Adult, 1 Egg Stage']\nall_quant_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)', 'Delta 15 N (o/oo)', 'Delta 13 C (o/oo)' ]\n\ncolumns = ['features', 'model', 'score']\n\nscore_df = pd.DataFrame(columns = columns)\n\nfor qual in all_qual_cols: \n  qual_cols = [col for col in X_train.columns if qual in col ]\n  for pair in combinations(all_quant_cols, 2):\n    cols = qual_cols + list(pair)\n\n    # Logistic Regression\n    LR = LogisticRegression(max_iter = 20000000000)\n    LR.fit(X_train[cols], y_train)  \n    LRscore = cross_val_score(LR, X_train[cols], y_train, cv = 5).mean()\n    score_df.loc[len(score_df.index)] = [cols, 'Logistic', LRscore]  \n\n    # Decision Tree\n    DTC = DecisionTreeClassifier()\n    param_grid = {'max_depth': [11,2,3,4,5,6,7,8,9,10, None]}\n    grid_search = GridSearchCV(DTC, param_grid, cv = 5)\n    grid_search.fit(X_train[cols], y_train)\n    DTCscore = grid_search.best_score_\n    score_df.loc[len(score_df.index)] = [cols, 'Decision Tree', DTCscore]  \n\n    # Random Forest\n    randomforest = RandomForestClassifier()\n    grid_search = GridSearchCV(randomforest, param_grid, cv = 5)\n    grid_search.fit(X_train[cols], y_train)\n    RF_score = grid_search.best_score_\n    score_df.loc[len(score_df.index)] = [cols, 'Random Forest', RF_score]\n\n    # SVM\n    param_grid = {'gamma': 10.0**np.arange(-5, 5)}\n    SVC_model = SVC()\n    grid_search = GridSearchCV(SVC_model, param_grid, cv = 5)\n    grid_search.fit(X_train[cols], y_train)\n    SVMscore = grid_search.best_score_\n    score_df.loc[len(score_df.index)] = [cols, \"SVM\", SVMscore]\n\nscore_df.sort_values(by='score', ascending=False).head(10)\n\n\n\n\n\n\n\n\nfeatures\nmodel\nscore\n\n\n\n\n60\n[Sex_FEMALE, Sex_MALE, Culmen Length (mm), Culmen Depth (mm)]\nLogistic\n0.988311\n\n\n62\n[Sex_FEMALE, Sex_MALE, Culmen Length (mm), Culmen Depth (mm)]\nRandom Forest\n0.988311\n\n\n66\n[Sex_FEMALE, Sex_MALE, Culmen Length (mm), Flipper Length (mm)]\nRandom Forest\n0.984465\n\n\n126\n[Island_Biscoe, Island_Dream, Island_Torgersen, Culmen Length (mm), Flipper Length (mm)]\nRandom Forest\n0.984389\n\n\n122\n[Island_Biscoe, Island_Dream, Island_Torgersen, Culmen Length (mm), Culmen Depth (mm)]\nRandom Forest\n0.984389\n\n\n120\n[Island_Biscoe, Island_Dream, Island_Torgersen, Culmen Length (mm), Culmen Depth (mm)]\nLogistic\n0.984389\n\n\n166\n[Island_Biscoe, Island_Dream, Island_Torgersen, Flipper Length (mm), Delta 13 C (o/oo)]\nRandom Forest\n0.984314\n\n\n138\n[Island_Biscoe, Island_Dream, Island_Torgersen, Culmen Length (mm), Delta 13 C (o/oo)]\nRandom Forest\n0.980543\n\n\n63\n[Sex_FEMALE, Sex_MALE, Culmen Length (mm), Culmen Depth (mm)]\nSVM\n0.980543\n\n\n134\n[Island_Biscoe, Island_Dream, Island_Torgersen, Culmen Length (mm), Delta 15 N (o/oo)]\nRandom Forest\n0.976621\n\n\n\n\n\n\n\nFor each model, the features, model type, and highest possible score was added to a dataframe. Sorting this dataframe by score revealed that Logistic Regression with Sex, Culmen Length and Culmen Depth as features produced the best classification.\n\n\n\ncitation: https://www.dreamstime.com/stock-illustration-d-penguin-teaches-math-render-numbers-image45736629\n\n\n\n\nEvaluate Chosen Model\nTo truly evaluate our model, we must evaluate how it performs on unseen testing data.\n\n# train with optimal features and model\nLR = LogisticRegression()\noptimal_features = ['Culmen Length (mm)', 'Culmen Depth (mm)','Sex_FEMALE', 'Sex_MALE']\nLR.fit(X_train[optimal_features], y_train)  \n\n/Users/lizrightmire/anaconda3/envs/ml-0451/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n\n\nLogisticRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegressionLogisticRegression()\n\n\n\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\ntest[\"Species\"] = test[\"Species\"].str.split().str.get(0)\n\n#test\nX_test, y_test = prepare_data(test)\nLR.score(X_test[optimal_features], y_test)\n\n1.0\n\n\nA score of 1.0 indicates that 100% of the penguins in the testing dataset were correctly classified by our model. Yippie!\nStepping back a little, let’s consider: does this make sense? Should we be able to determine a penguin species based on its sex, culmen length, and culmen depth?\nYes, it seems logical that different species of penguins have different culmen dimensions. I am also not surprised that sex is an important qualitative feature to consider, as penguin size, and consequently beak dimensions, vary based on sex. For example, female Gentoo penguins may have similar culmen lengths to a male Adelie, so sex is required to determine species.\nTo be sure, let’s create a scatterplot of these 3 features and look at the decision regions produced by our logistic algorithm.\n\nfrom matplotlib.patches import Patch\nfrom matplotlib import pyplot as plt\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (7, 3))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\nFor the training data:\n\n# training data\nplot_regions(LR, X_train[optimal_features], y_train)\n\n\n\n\n\n\n\n\nFor the testing data:\n\n# testing data\nplot_regions(LR, X_test[optimal_features], y_test)\n\n\n\n\n\n\n\n\nYes, separating penguins by sex creates very clear clusters of points by species in the testing data, which transfers perfectly to the points in the testing data.\nAnother way to evaluate would be to look at a confusion matrix for this model\n\nfrom sklearn.metrics import confusion_matrix\n\n#actual\n#predicted\n\ny_test_pred = LR.predict(X_test[optimal_features]) # guesses for each data\n\ncm = confusion_matrix(y_test, y_test_pred)\n\nfor i in range(3):\n    for j in range(3):\n        print(f\"There were {cm[i,j]} {le.classes_[i]} penguin(s) who were classified as {le.classes_[j]}.\")\n\nThere were 31 Adelie penguin(s) who were classified as Adelie.\nThere were 0 Adelie penguin(s) who were classified as Chinstrap.\nThere were 0 Adelie penguin(s) who were classified as Gentoo.\nThere were 0 Chinstrap penguin(s) who were classified as Adelie.\nThere were 11 Chinstrap penguin(s) who were classified as Chinstrap.\nThere were 0 Chinstrap penguin(s) who were classified as Gentoo.\nThere were 0 Gentoo penguin(s) who were classified as Adelie.\nThere were 0 Gentoo penguin(s) who were classified as Chinstrap.\nThere were 26 Gentoo penguin(s) who were classified as Gentoo.\n\n\nZero penguins were mis-classified. This makes sense because we got our logistic regression model had an accuracy of 1.0!\nThe plot below is another way to visualize the confusion matrix. For an accuracy of 1.0, we would expect zeros in every box execept for those on the diagonal, meaning that zero penguins were misclassified.\n\n# plot confusion matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\ncm_df = pd.DataFrame((cm), index = ['Gentoo','Chinstrap ','Adelie'], columns = ['Gentoo','Chinstrap','Adelie'])\ndisplay_labels = [\"Adelie\", \"Chinstrap\", \"Gentoo\"]\nConfusionMatrixDisplay(cm, display_labels = display_labels).plot(\n    include_values=True)"
  },
  {
    "objectID": "posts/Goal-Setting/goal-setting.html",
    "href": "posts/Goal-Setting/goal-setting.html",
    "title": "Goal Setting",
    "section": "",
    "text": "Liz Rightmire\n\n\nThe knowledge we’ll develop in CSCI 0451 can be broadly divided into four main areas:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nEvery student should grow toward each of these areas, but you can choose to specialize if you’d like! If there are one or two of these categories on which you’d especially like to focus, list them below. Feel free to include any details that you’d like – this can help me tailor the course content to your interests.\nAs I progress through the computer science major, I have developed a specific interest in data science and machine learning – it’s what I hope to do postgrad. I’ve been looking forward to this class for a long time, and when looking at my schedule, it seems within the realm of possibility to make this class a priority. I have a bit of experience with with implementation and experimentation of ML through a data science internship last summer, but I am far from an expert :). Therefore, I hope to apply most of my focus to theory (I want to better understand HOW these algorithms work and leverage my mathematical experience!) and Social Responsibliity (with an aspired career in data science, I am concerned about my impact and I want to take advantage of my liberal arts education to understand the harm that can be done in this industry.)\n\n\n\n\n\nMost blog posts will require around 5-8 hours on average to complete, plus time for revisions in response to feedback. Blog posts will most frequently involve a mix of mathematical problem-solving, coding, experimentation, and written discussion. Some blog posts will ask you to critically discuss recent readings in an essay-like format.\nI hope to do most of the blog posts. I tend to work at a slower rate than the average student, and considering that they take 5-8 hours to complete, I want to leave room in my goal of 10hrs/week of ML for readings and warm-ups. I see myself learning a lot from the blog posts, so I want to do as many as possible without over-extending myself. I find it challenging to quantify a specific number of blog posts at this time. Instead, it feels more reasonable to say that knowing that we’ll have check-ins throughout the semester with the average numbers completed by the class, I hope my statistic will place me in an ambitous range.\nWhen I need to prioritize which blog posts to complete, I want to cover all categories but place special emphasis on Theory and Social Responsibility. I hope to propose and complete one additional blog post on Social Responsibility. Knowing myself, I don’t think it will be challenging to submit my work by the best-by date and I want to give myself flexibility to invest extra time into blog posts that particularly interest me!\nI believe that completing revisions is where I’ll learn the most, so I want to revise most (5?) of my blog posts to “no revisions suggested.”\n\n\n\nYou make a choice each day about how to show up for class: whether you’ll be prepared, whether you’ll engage with me and your peers in a constructive manner; and whether you’ll be active during lecture and discussions.\nAn especially important form of course presence is the daily warmup. We’ll spend the first 10-15 minutes of most class periods on warmup activities. You’re expected to have prepared the warmup activity ahead of time (this means you’ll need to have completed the readings as well). Each time, we’ll sort into groups of 5-6 students, and one of you (randomly selected) will be responsible for presenting the activity on the whiteboard. If you’re not feeling prepared to present the activity, you can “pass” to the next person, or ask for help along the way.\nI aspire to do all of the readings – including some optional theory readings – as well as all of the warm-ups to the best of my ability. It doesn’t feel productive to place a maximum number of “passes” because I trust my effort and intentions in doing my best work; instead, I’ll try to attend student hours if I get stumped. I might need help from classmates sometimes, and I think that’s ok.\nBefore class, I aspire to preview the in-class coding we’ll be doing so that I prep myself well for understanding the content.\nI have already begun working with some classmates outside of class, so I hope to sometimes be the one to organize work times.\nSomething I want to work on is my presentation skills. I presented on an algorithm for my J-Term class, and I felt poorly about how it went. Each time I’m chosen to present the warm-up in ML, I want to treat it as practice speaking in front of others and engaging my peers in discussion. I’m not one to speak often in class, but I aspire to ask a few questions over the semester and maybe even answer some questions. More practical for me, perhaps, is to challenge myself to attend student hours to ask specific questions when I get stuck.\n\n\n\nTo finish off the course, you’ll complete a long-term project that showcases your interests and skills. You’ll be free to propose and pursue a topic. My expectation is that most projects will move significantly beyond the content covered in class in some way: you might implement a new algorithm, study a complex data set in depth, or conduct a series of experiments related to assessing algorithmic bias in a certain class of algorithm. You’ll be expected to complete this project in small groups (of your choosing), and update us at a few milestones along the way.\nPlease share a bit about what kind of topic might excite you, and set a few goals about how you plan to show up as a constructive team-member and co-inquirer (see the ideas for some inspiration).\nI look forward to working on a culmianting project with some classmates! Right now, I think I’ll be interested in finding a complex dataset and applying some of the techniques we’ve learned in class as well as trying some new techniques. At the end of the project, I want to feel as though I “pulled my weight” with technical contributions, but also practice my interpersonal teamwork skills and hold teammates accountable for work. The final presentation will be a great opportunity for me to apply what I’ve been practicing in leading warm-ups."
  },
  {
    "objectID": "posts/Goal-Setting/goal-setting.html#what-youll-learn",
    "href": "posts/Goal-Setting/goal-setting.html#what-youll-learn",
    "title": "Goal Setting",
    "section": "",
    "text": "The knowledge we’ll develop in CSCI 0451 can be broadly divided into four main areas:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nEvery student should grow toward each of these areas, but you can choose to specialize if you’d like! If there are one or two of these categories on which you’d especially like to focus, list them below. Feel free to include any details that you’d like – this can help me tailor the course content to your interests.\nAs I progress through the computer science major, I have developed a specific interest in data science and machine learning – it’s what I hope to do postgrad. I’ve been looking forward to this class for a long time, and when looking at my schedule, it seems within the realm of possibility to make this class a priority. I have a bit of experience with with implementation and experimentation of ML through a data science internship last summer, but I am far from an expert :). Therefore, I hope to apply most of my focus to theory (I want to better understand HOW these algorithms work and leverage my mathematical experience!) and Social Responsibliity (with an aspired career in data science, I am concerned about my impact and I want to take advantage of my liberal arts education to understand the harm that can be done in this industry.)"
  },
  {
    "objectID": "posts/Goal-Setting/goal-setting.html#what-youll-achieve",
    "href": "posts/Goal-Setting/goal-setting.html#what-youll-achieve",
    "title": "Goal Setting",
    "section": "",
    "text": "Most blog posts will require around 5-8 hours on average to complete, plus time for revisions in response to feedback. Blog posts will most frequently involve a mix of mathematical problem-solving, coding, experimentation, and written discussion. Some blog posts will ask you to critically discuss recent readings in an essay-like format.\nI hope to do most of the blog posts. I tend to work at a slower rate than the average student, and considering that they take 5-8 hours to complete, I want to leave room in my goal of 10hrs/week of ML for readings and warm-ups. I see myself learning a lot from the blog posts, so I want to do as many as possible without over-extending myself. I find it challenging to quantify a specific number of blog posts at this time. Instead, it feels more reasonable to say that knowing that we’ll have check-ins throughout the semester with the average numbers completed by the class, I hope my statistic will place me in an ambitous range.\nWhen I need to prioritize which blog posts to complete, I want to cover all categories but place special emphasis on Theory and Social Responsibility. I hope to propose and complete one additional blog post on Social Responsibility. Knowing myself, I don’t think it will be challenging to submit my work by the best-by date and I want to give myself flexibility to invest extra time into blog posts that particularly interest me!\nI believe that completing revisions is where I’ll learn the most, so I want to revise most (5?) of my blog posts to “no revisions suggested.”\n\n\n\nYou make a choice each day about how to show up for class: whether you’ll be prepared, whether you’ll engage with me and your peers in a constructive manner; and whether you’ll be active during lecture and discussions.\nAn especially important form of course presence is the daily warmup. We’ll spend the first 10-15 minutes of most class periods on warmup activities. You’re expected to have prepared the warmup activity ahead of time (this means you’ll need to have completed the readings as well). Each time, we’ll sort into groups of 5-6 students, and one of you (randomly selected) will be responsible for presenting the activity on the whiteboard. If you’re not feeling prepared to present the activity, you can “pass” to the next person, or ask for help along the way.\nI aspire to do all of the readings – including some optional theory readings – as well as all of the warm-ups to the best of my ability. It doesn’t feel productive to place a maximum number of “passes” because I trust my effort and intentions in doing my best work; instead, I’ll try to attend student hours if I get stumped. I might need help from classmates sometimes, and I think that’s ok.\nBefore class, I aspire to preview the in-class coding we’ll be doing so that I prep myself well for understanding the content.\nI have already begun working with some classmates outside of class, so I hope to sometimes be the one to organize work times.\nSomething I want to work on is my presentation skills. I presented on an algorithm for my J-Term class, and I felt poorly about how it went. Each time I’m chosen to present the warm-up in ML, I want to treat it as practice speaking in front of others and engaging my peers in discussion. I’m not one to speak often in class, but I aspire to ask a few questions over the semester and maybe even answer some questions. More practical for me, perhaps, is to challenge myself to attend student hours to ask specific questions when I get stuck.\n\n\n\nTo finish off the course, you’ll complete a long-term project that showcases your interests and skills. You’ll be free to propose and pursue a topic. My expectation is that most projects will move significantly beyond the content covered in class in some way: you might implement a new algorithm, study a complex data set in depth, or conduct a series of experiments related to assessing algorithmic bias in a certain class of algorithm. You’ll be expected to complete this project in small groups (of your choosing), and update us at a few milestones along the way.\nPlease share a bit about what kind of topic might excite you, and set a few goals about how you plan to show up as a constructive team-member and co-inquirer (see the ideas for some inspiration).\nI look forward to working on a culmianting project with some classmates! Right now, I think I’ll be interested in finding a complex dataset and applying some of the techniques we’ve learned in class as well as trying some new techniques. At the end of the project, I want to feel as though I “pulled my weight” with technical contributions, but also practice my interpersonal teamwork skills and hold teammates accountable for work. The final presentation will be a great opportunity for me to apply what I’ve been practicing in leading warm-ups."
  }
]